config:
  llms:
    answer:
      provider: groq
      model: qwen/qwen3-32b
      temperature: 0.3
      reasoning_effort: "none"

    deterministic:
      provider: groq
      model: qwen/qwen3-32b
      temperature: 0.0
      reasoning_effort: "none"

    code:
      provider: groq
      model: qwen/qwen3-32b
      temperature: 0.3
      reasoning_effort: "none"

    small:
      provider: ollama
      model: qwen3:0.6b
      base_url: http://127.0.0.1:11434
      temperature: 0.3
      reasoning: false
  embeddings:
    provider: ollama
    model: nomic-embed-text
    dimensions: 768
    base_url: http://127.0.0.1:11434
    num_ctx: 8192
  vector_store:
    provider: faiss
  trace:
    provider: langfuse
  db:
    connection_string: sqlite:///assistant.db
  profile: dev